import os
import pandas as pd
import sqlite3
from datetime import datetime
import imaplib
import email
from email.header import decode_header
import tempfile
from openpyxl import load_workbook
import logging
from dotenv import load_dotenv

load_dotenv()
logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")

# ------------------ –ü–æ—á—Ç–æ–≤—ã–µ —É—Ç–∏–ª–∏—Ç—ã ------------------
def get_email_credentials():
    user = os.getenv("EMAIL_USER")
    pwd  = os.getenv("EMAIL_PASSWORD")
    srv  = os.getenv("EMAIL_SERVER", "imap.gmail.com")
    missing = [v for v in ("EMAIL_USER","EMAIL_PASSWORD","EMAIL_SERVER") if not os.getenv(v)]
    if missing:
        raise RuntimeError(f"–ù–µ –Ω–∞–π–¥–µ–Ω—ã –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è: {', '.join(missing)}.")
    return user, pwd, srv

def connect_to_email():
    user, pwd, srv = get_email_credentials()
    mail = imaplib.IMAP4_SSL(srv)
    mail.login(user, pwd)
    return mail

def extract_date_from_subject(subject):
    try:
        for part in subject.split():
            try:
                return datetime.strptime(part, "%d.%m.%Y").strftime("%Y-%m-%d")
            except ValueError:
                continue
    except Exception:
        pass
    return datetime.now().strftime("%Y-%m-%d")

def decode_mime_words(s):
    decoded_fragments = decode_header(s)
    return ''.join([
        fragment.decode(encoding or 'utf-8') if isinstance(fragment, bytes) else fragment
        for fragment, encoding in decoded_fragments
    ])

def find_latest_purchase_file():
    try:
        logging.info("–ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –ø–æ—á—Ç–µ...")
        mail = connect_to_email()
        logging.info("‚úÖ –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –ø–æ—á—Ç–µ —É—Å–ø–µ—à–Ω–æ")

        mail.select("inbox")
        logging.info("üîç –ü–æ–∏—Å–∫ –ø–∏—Å–µ–º —Å —Ç–µ–º–æ–π, —Å–æ–¥–µ—Ä–∂–∞—â–µ–π '–∑–∞–∫—É–ø–∫'...")
        result, data = mail.search(None, "ALL")
        if result != "OK":
            logging.warning("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –ø–∏—Å—å–º–∞")
            return None, None

        email_ids = data[0].split()[::-1][:10]
        logging.info(f"üì® –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ {len(email_ids)} –ø–∏—Å–µ–º")

        for eid in email_ids:
            result, msg_data = mail.fetch(eid, "(RFC822)")
            if result != "OK":
                continue

            msg = email.message_from_bytes(msg_data[0][1])
            subject_raw = msg.get("Subject", "")
            subject = decode_mime_words(subject_raw)

            if "–∑–∞–∫—É–ø–∫" not in subject.lower():
                continue

            logging.info(f"üì¶ –ù–∞–π–¥–µ–Ω–æ –ø–∏—Å—å–º–æ —Å —Ç–µ–º–æ–π: {subject}")

            for part in msg.walk():
                if part.get_content_maintype() == "multipart":
                    continue
                if part.get("Content-Disposition") is None:
                    continue

                filename_raw = part.get_filename()
                if not filename_raw:
                    continue
                filename = decode_mime_words(filename_raw)

                if filename.lower().endswith((".xls", ".xlsx")):
                    logging.info(f"‚¨áÔ∏è –°–∫–∞—á–∏–≤–∞–Ω–∏–µ –≤–ª–æ–∂–µ–Ω–∏—è: {filename}")
                    payload = part.get_payload(decode=True)
                    if not payload:
                        continue
                    with tempfile.NamedTemporaryFile(delete=False, suffix=".xlsx") as tmp:
                        tmp.write(payload)
                        return tmp.name, subject

        logging.warning("üì≠ –ù–µ –Ω–∞–π–¥–µ–Ω –ø–æ–¥—Ö–æ–¥—è—â–∏–π —Ñ–∞–π–ª –≤–ª–æ–∂–µ–Ω–∏—è –≤ –ø–∏—Å—å–º–∞—Ö")
        return None, None

    except Exception as e:
        logging.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ find_latest_purchase_file: {e}")
        return None, None

def update_purchases_data():
    DB_PATH = r"C:\\Users\\user\\Desktop\\–ü—Ä–æ–µ–∫—Ç—ã\\projects\\sales_airflow_project\\db.db"

    try:
        logging.info("–ü–æ–∏—Å–∫ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ —Ñ–∞–π–ª–∞ –∑–∞–∫—É–ø–æ–∫...")
        path, subj = find_latest_purchase_file()
        if not path:
            logging.warning("üì≠ –§–∞–π–ª –∑–∞–∫—É–ø–æ–∫ –Ω–µ –Ω–∞–π–¥–µ–Ω")
            return False

        report_date = extract_date_from_subject(subj)
        wb = load_workbook(path, data_only=True)
        ws = wb.active

        header = [str(cell.value).strip().lower() if cell.value else "" for cell in ws[1]]
        col_map = {
            '–ø–æ—Å—Ç–∞–≤—â–∏–∫': 1,
            '–Ω–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä–∞': 0,
            '–∫–æ–ª-–≤–æ': 2,
            '—Ü–µ–Ω–∞': 3,
            '—Å—É–º–º–∞': 4,
            '—Å—É–º–º–∞ —Å –Ω–¥—Å': 5
        }

        data = []
        for row in ws.iter_rows(min_row=3, values_only=True):
            supplier = row[col_map['–ø–æ—Å—Ç–∞–≤—â–∏–∫']]
            product = row[col_map['–Ω–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä–∞']]
            quantity = row[col_map['–∫–æ–ª-–≤–æ']]
            price_per_unit = row[col_map['—Ü–µ–Ω–∞']]
            total = row[col_map['—Å—É–º–º–∞']]
            total_with_vat = row[col_map['—Å—É–º–º–∞ —Å –Ω–¥—Å']]

            if not supplier or not product or not isinstance(quantity, (int, float)):
                continue

            data.append({
                "supplier": str(supplier).strip(),
                "product": str(product).strip(),
                "quantity": quantity,
                "price_per_unit": price_per_unit or 0,
                "total": total or 0,
                "total_with_vat": total_with_vat or 0,
                "report_date": report_date
            })

        if not data:
            logging.warning("‚ùå –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –∑–∞–∫—É–ø–æ–∫")
            return False

        df = pd.DataFrame(data)
        logging.info("üîß –°–æ–∑–¥–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü—ã purchases –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏...")
        conn = sqlite3.connect(DB_PATH)
        conn.execute('''CREATE TABLE IF NOT EXISTS purchases (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            supplier TEXT,
            product TEXT,
            quantity REAL,
            price_per_unit REAL,
            total REAL,
            total_with_vat REAL,
            report_date TEXT
        )''')
        logging.info("üì• –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö...")
        df.to_sql('purchases', conn, if_exists='append', index=False)
        conn.commit()
        conn.close()
        os.remove(path)
        logging.info("‚úÖ –ó–∞–∫—É–ø–∫–∏ –æ–±–Ω–æ–≤–ª–µ–Ω—ã")
        return True

    except Exception as e:
        logging.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ –∑–∞–∫—É–ø–æ–∫: {e}")
        return False

if __name__ == "__main__":
    update_purchases_data()
